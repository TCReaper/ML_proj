{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6e6cfe",
   "metadata": {},
   "source": [
    "# Part 1: Estimate Emission Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b492c5",
   "metadata": {},
   "source": [
    "### Function to process the file\n",
    "\n",
    "##### This will help to give us the tag counts, word-tag pair counts, set of words (vocabulary) and gives a list of all the sentences in the file. These different lists and counts will be used in later parts of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0fac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    # we make use of the default library \"collections\" to make processing the tags and word-tag pairs easier\n",
    "    import collections #used for counting\n",
    "    tag_count = collections.defaultdict(int)  # counting for tags\n",
    "    word_tag_count = collections.defaultdict(int)  # counting for word-tag pairs\n",
    "    vocabulary = set()  # stores unique words\n",
    "    sentences = [] # store all the sentences\n",
    "    current_sentence = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        # reading file line-by-line\n",
    "        for line in file:\n",
    "            stripped_line = line.strip() #removes the /n and then splits it to separete the word and its label\n",
    "            if stripped_line:  # check if there even is a word or tag in the line\n",
    "                word, tag = stripped_line.split()  # Split line into word and tag\n",
    "                word_tag_count[(word, tag)] += 1\n",
    "                tag_count[tag] += 1\n",
    "                vocabulary.add(word) #doesnt add duplicates\n",
    "                current_sentence.append(word)\n",
    "            else:\n",
    "                if current_sentence: \n",
    "                    # add current sentence to sentences then restart the count\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "\n",
    "    return tag_count, word_tag_count, vocabulary, sentences\n",
    "\n",
    "\n",
    "#tag count : dictionary with the count of each tag e.g ('B-NP') : 45\n",
    "#word_tag_count : dictionary with the count of each word-tag pair e.g ('Municipal','B-NP') : 1\n",
    "\n",
    "tag_count, word_tag_count, vocabulary, sentences = process_file('EN/train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c306f1",
   "metadata": {},
   "source": [
    "### Function to write the output file\n",
    "\n",
    "##### This function will write in the predictions to a specified file path, leaving a new line between sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b65e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(predictions, output_filepath):\n",
    "    # to use this function effectively, \"predictions\" should be a list of sentences\n",
    "    \n",
    "    # open the output file for writing\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as file:\n",
    "        for sentence in predictions:\n",
    "            for word, tag in sentence:\n",
    "                # write each word and its predicted tag to the file, with a spacing to separate.\n",
    "                file.write(f\"{word} {tag}\\n\")\n",
    "            # add a new line, to separate sentences\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed65eb8",
   "metadata": {},
   "source": [
    "## Part 1a, 5 points (Function to estimate emission parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61488a85",
   "metadata": {},
   "source": [
    "###### We have a function to calculate the emission probability of a given word, based on the tag and word-tag pair counts. We also have another function to calculate the emission probability of all the different words present in the file.\n",
    "\n",
    "###### We mainly make use of the latter in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4718891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_one_emission_probabilities(x, y, tag_count, word_tag_count):\n",
    "    \n",
    "    # get the total times y->x occurs\n",
    "    word_tag_freq = word_tag_count.get((x, y), 0)\n",
    "    # total times y appears\n",
    "    tag_total_freq = tag_count.get(y, 1)\n",
    "    \n",
    "    return word_tag_freq / tag_total_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfb4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_all_emission_probabilities(tag_count, word_tag_count):\n",
    "  \n",
    "    emission_probabilities = {}\n",
    "    # iterate through all the word tag pairs to get all the emission probabilities\n",
    "    # store the results in the dictionary emission_probabilities\n",
    "    for (word, tag), count in word_tag_count.items():\n",
    "        # using the expression that utilises MLE\n",
    "        emission_probabilities[(word, tag)] = count / tag_count[tag] \n",
    "        \n",
    "    return emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99fe300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to store the emission probabilities in a variable\n",
    "emission_probabilities = estimate_all_emission_probabilities(tag_count, word_tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c2355",
   "metadata": {},
   "source": [
    "## Part 1b, 10 points (Accounting for unknown word tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cba93",
   "metadata": {},
   "source": [
    "###### Again, we have a function to calculate the emission probability of a given word, based on the tag and word-tag pair counts. We also have another function to calculate the emission probability of all the different words present in the file.\n",
    "\n",
    "###### We mainly make use of the latter in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0200890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_probability_with_unknown(tag, word, tag_count, word_tag_count, vocabulary, k=0.1):\n",
    "    \n",
    "    # total times y appears + k\n",
    "    tag_total_freq = tag_count.get(tag, 0) + k\n",
    "    \n",
    "    # Check if the word was seen in the training set; if not, use the special UNK token\n",
    "    # e(x|y) = k/(count(y)+k) if word token is UNK\n",
    "    if word not in vocabulary:\n",
    "        word = '#UNK#'\n",
    "        word_tag_freq = k\n",
    "        return word_tag_freq / tag_total_freq\n",
    "    \n",
    "    # get the total times y->x occurs\n",
    "    word_tag_freq = word_tag_count.get((word, tag), 0)\n",
    "  \n",
    "    return word_tag_freq / tag_total_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595ef8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_all_emission_probabilities_with_unknown(tag_count, word_tag_count, k =0.1):\n",
    "  \n",
    "    emission_probabilities = {}\n",
    "    # iterate through all the word tag pairs to get all the emission probabilities\n",
    "    # store the results in the dictionary emission_probabilities\n",
    "    # accounts for when the word token x appears in the training set\n",
    "    for (word, tag), count in word_tag_count.items():\n",
    "        \n",
    "        emission_probabilities[(word, tag)] = count / (tag_count[tag]+k)\n",
    "    \n",
    "    # add the emission probabilities for when the word token x is #UNK#\n",
    "    for tag, count in tag_count.items():\n",
    "        emission_probabilities[(\"#UNK#\", tag)] = count / (tag_count[tag]+k)\n",
    "    return emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a39b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to override the prevous emission probabilities\n",
    "emission_probabilities = estimate_all_emission_probabilities_with_unknown(tag_count, word_tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9ef45",
   "metadata": {},
   "source": [
    "## Part 1c, 10 points (simple sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f4b80",
   "metadata": {},
   "source": [
    "##### We essentially just produce the tag, y* = arg max e(x|y) over all y for each word in a sequence. We come up with a function that predicts the best tag for 1 word, and another function that predicts the best tag for a sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da43cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_tag(word, emission_probabilities, vocabulary,tag_count):\n",
    "    # use UNK token if the word is not in the vocabulary\n",
    "    best_tag = None\n",
    "\n",
    "    if word not in vocabulary:\n",
    "        word = '#UNK#'\n",
    "        best_tag = max(tag_count)\n",
    "#         return '#UNK#'\n",
    "\n",
    "    # initialise the variables to keep track of the best tag and its highest probability\n",
    "    max_probability = -1  # Start with a very low probability\n",
    "\n",
    "    # iterate over all possible tags for the word in the emission probabilities\n",
    "    for (current_word, tag), probability in emission_probabilities.items():\n",
    "        if current_word == word and probability > max_probability:\n",
    "            max_probability = probability\n",
    "            best_tag = tag\n",
    "\n",
    "    return word, best_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9e459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function considers the fact that the file in filpath \n",
    "# has mutiple sentences separated by a new line\n",
    "# thus it returns predictions in a list of sentences\n",
    "def predict_all_tags(filepath, emission_probabilities, vocabulary, tag_count):\n",
    "    predictions = []\n",
    "    current_sentence = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            word = line.strip()\n",
    "            if word:  # Ensure the line is not empty\n",
    "                word, best_tag = predict_one_tag(word, emission_probabilities, vocabulary, tag_count)\n",
    "                current_sentence.append((word, best_tag))\n",
    "            else:\n",
    "                if current_sentence:\n",
    "                    predictions.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "        if current_sentence:\n",
    "                    predictions.append(current_sentence)\n",
    "    # what is returned here, is a list of sentences\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21db019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function to predict all tags in the file\n",
    "predictions = predict_all_tags(\"EN/dev.in\", emission_probabilities, vocabulary, tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470b5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_file(predictions, \"EN/dev.p1.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a30b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 17330\n",
      "\n",
      "#Correct Entity : 9251\n",
      "Entity  precision: 0.5338\n",
      "Entity  recall: 0.7020\n",
      "Entity  F: 0.6064\n",
      "\n",
      "#Correct Sentiment : 8319\n",
      "Sentiment  precision: 0.4800\n",
      "Sentiment  recall: 0.6312\n",
      "Sentiment  F: 0.5453\n"
     ]
    }
   ],
   "source": [
    "# evaluare the scores of the simple sentiment analysis system\n",
    "!python3 EvalScript/evalResult.py EN/dev.out EN/dev.p1.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
